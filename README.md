# Sistema de AnotaciÃ³n de Video

## ğŸ‘¥ Integrantes

* [Jhonatan CastaÃ±o](https://github.com/JhonatanCI)
* [AndrÃ©s Pino](https://github.com/AndresPin0)

**Proyecto Final - Inteligencia Artificial 1**

Un sistema completo para la detecciÃ³n y clasificaciÃ³n de actividades humanas en tiempo real utilizando MediaPipe y tÃ©cnicas de aprendizaje automÃ¡tico.

## ğŸ¬ PresentaciÃ³n en vÃ­deo

[![PresentaciÃ³n en vÃ­deo](https://img.youtube.com/vi/2BeW1TyJGks/0.jpg)](https://youtu.be/2BeW1TyJGks)

## ğŸ“‹ DescripciÃ³n del Proyecto

Este sistema permite analizar videos en tiempo real para detectar y clasificar las siguientes actividades:

- **Caminar hacia la cÃ¡mara**: Persona se acerca frontalmente
- **Caminar alejÃ¡ndose**: Persona se aleja de espaldas
- **Girar 90 grados**: Un cuarto de vuelta a la izquierda o derecha
- **Girar 180 grados**: Media vuelta completa
- **Sentarse**: Desde de pie a sentado en silla
- **Ponerse de pie**: Desde sentado a de pie

### CaracterÃ­sticas Principales

- **DetecciÃ³n de poses en tiempo real** usando MediaPipe
- **ClasificaciÃ³n de actividades** con mÃºltiples algoritmos de ML
- **AnÃ¡lisis de inclinaciones laterales** y movimientos articulares
- **Interfaz grÃ¡fica intuitiva** para visualizaciÃ³n en tiempo real
- **Pipeline completo** desde extracciÃ³n hasta entrenamiento
- **AnÃ¡lisis exploratorio** de datos con visualizaciones

## ğŸ—ï¸ Arquitectura del Sistema

```
sistema_anotacion_video/
â”œâ”€â”€ src/                          # CÃ³digo fuente principal del sistema en tiempo real y mÃ³dulos centrales
â”‚   â”œâ”€â”€ __init__.py              # Inicializador del paquete src
â”‚   â”œâ”€â”€ main.py                  # Punto de entrada para la aplicaciÃ³n GUI en tiempo real
â”‚   â”œâ”€â”€ pose_detection/          # MÃ³dulo para la detecciÃ³n de poses con MediaPipe
â”‚   â”œâ”€â”€ activity_classifier/     # MÃ³dulo para la clasificaciÃ³n de actividades
â”‚   â”œâ”€â”€ gui/                     # MÃ³dulo para la interfaz grÃ¡fica de usuario (PyQt5)
â”‚   â”œâ”€â”€ video_capture/          # MÃ³dulo para la captura y manejo de video
â”‚   â”œâ”€â”€ utils/                   # Utilidades generales y funciones auxiliares
â”‚   â”œâ”€â”€ data_analysis/           # (Posiblemente) MÃ³dulos auxiliares para anÃ¡lisis de datos
â”‚   â”œâ”€â”€ extract_features/        # (Posiblemente) MÃ³dulos auxiliares para extracciÃ³n de caracterÃ­sticas
â”‚   â””â”€â”€ train_classifier/        # (Posiblemente) MÃ³dulos auxiliares para entrenamiento de clasificadores
â”œâ”€â”€ docs/                         # DocumentaciÃ³n, incluyendo imÃ¡genes, diagramas y reporte en pdf
â”‚   â””â”€â”€ diagramas/               # Diagramas del sistema (bloques, flujo)
â”œâ”€â”€ videos/                       # Videos de entrada para entrenamiento, organizados por actividad
â”œâ”€â”€ data/                         # Datos procesados (e.g., caracterÃ­sticas extraÃ­das en CSV)
â”œâ”€â”€ models/                       # Modelos de Machine Learning entrenados y su evaluaciÃ³n
â”‚   â””â”€â”€ evaluation/              # Reportes de evaluaciÃ³n, comparativas de modelos
â”‚   â””â”€â”€ plots/                   # GrÃ¡ficos de evaluaciÃ³n de modelos
â”œâ”€â”€ analysis/                     # Resultados del anÃ¡lisis exploratorio de datos
â”‚   â”œâ”€â”€ reports/                 # Reportes de anÃ¡lisis (e.g., analysis_report.txt)
â”‚   â”œâ”€â”€ plots/                   # GrÃ¡ficos y visualizaciones del anÃ¡lisis
â”‚   â””â”€â”€ statistics/              # EstadÃ­sticas detalladas de los datos
â”œâ”€â”€ reports/                      # (PropÃ³sito a confirmar, podrÃ­a ser para reportes generales o logs)
â”œâ”€â”€ extract_video_features.py   # Script para extraer caracterÃ­sticas de los videos
â”œâ”€â”€ train_classifier.py         # Script para entrenar los modelos de clasificaciÃ³n
â”œâ”€â”€ generate_report_plots.py    # Script para generar anÃ¡lisis exploratorio y visualizaciones (antes data_analysis.py)
â”œâ”€â”€ run_pipeline.py             # Script para ejecutar el pipeline completo (extracciÃ³n, entrenamiento, evaluaciÃ³n)
â”œâ”€â”€ requirements.txt            # Dependencias del proyecto Python
â”œâ”€â”€ README.md                     # Este archivo, con la descripciÃ³n general del proyecto
â””â”€â”€ .gitignore                    # Especifica archivos y directorios ignorados por Git
```

## ğŸ§± Diagrama de Bloques del Sistema

![Diagrama de Bloques del Sistema](docs/diagramas/diagrama_bloques_sistema.png)

## âš™ï¸ Diagrama de Flujo: Pipeline de Entrenamiento

![Diagrama de Flujo: Pipeline de Entrenamiento](docs/diagramas/diagrama_flujo_pipeline_entrenamiento.png)

## ğŸ‘ï¸ Diagrama de Flujo: DetecciÃ³n de Actividad en Tiempo Real

![Diagrama de Flujo: DetecciÃ³n de Actividad en Tiempo Real](docs/diagramas/diagrama_flujo_pipeline_deteccion_tiempo_real.png)

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### Prerequisitos

- Python 3.8 o superior
- CÃ¡mara web funcional
- Sistema operativo: Windows, macOS, o Linux

### InstalaciÃ³n

1. **Clonar el repositorio**:
```bash
git clone https://github.com/AndresPin0/sistema_anotacion_video.git
cd sistema_anotacion_video
```

2. **Crear entorno virtual** (recomendado):
```bash
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
```

3. **Instalar dependencias**:
```bash
pip install -r requirements.txt
```

4. **Verificar instalaciÃ³n**:
```bash
python src/main.py
```

## ğŸ“¹ PreparaciÃ³n de Datos

### Estructura de Videos

Los videos de entrenamiento deben organizarse en la siguiente estructura:

```
videos/
â”œâ”€â”€ caminar_hacia/
â”‚   â”œâ”€â”€ video1.mp4
â”‚   â”œâ”€â”€ video2.mp4
â”‚   â””â”€â”€ video3.mp4
â”œâ”€â”€ caminar_regreso/
â”‚   â”œâ”€â”€ video1.mp4
â”‚   â”œâ”€â”€ video2.mp4
â”‚   â””â”€â”€ video3.mp4
â”œâ”€â”€ girar_90/
â”‚   â”œâ”€â”€ video1.mp4
â”‚   â”œâ”€â”€ video2.mp4
â”‚   â””â”€â”€ video3.mp4
â”œâ”€â”€ girar_180/
â”‚   â”œâ”€â”€ video1.mp4
â”‚   â”œâ”€â”€ video2.mp4
â”‚   â””â”€â”€ video3.mp4
â”œâ”€â”€ sentarse/
â”‚   â”œâ”€â”€ video1.mp4
â”‚   â”œâ”€â”€ video2.mp4
â”‚   â””â”€â”€ video3.mp4
â””â”€â”€ ponerse_de_pie/
â”‚   â”œâ”€â”€ video1.mp4
â”‚   â”œâ”€â”€ video2.mp4
â”‚   â””â”€â”€ video3.mp4
```

### Recomendaciones para GrabaciÃ³n

âœ… **Hacer**:
- Persona completa visible en el frame
- Buena iluminaciÃ³n (evitar sombras fuertes)
- Fondo despejado
- CÃ¡mara estable
- DuraciÃ³n: 5-15 segundos por video
- MÃ­nimo 3 videos por actividad

âŒ **Evitar**:
- Personas parcialmente cortadas
- IluminaciÃ³n muy pobre
- Movimientos muy rÃ¡pidos
- MÃºltiples personas en el frame

## ğŸ”„ Pipeline de Entrenamiento

### OpciÃ³n 1: Pipeline Automatizado (Recomendado)

Ejecutar todo el proceso de una vez:

```bash
# Pipeline completo
python run_pipeline.py

# Pipeline rÃ¡pido (sin Grid Search)
python run_pipeline.py --quick_run

# Para pruebas con pocos datos
python run_pipeline.py --max_videos 2 --max_frames 100 --quick_run
```

### OpciÃ³n 2: EjecuciÃ³n Manual por Pasos

#### Paso 1: ExtracciÃ³n de CaracterÃ­sticas
```bash
python extract_video_features.py
```

#### Paso 2: AnÃ¡lisis Exploratorio
```bash
python generate_report_plots.py
```

#### Paso 3: Entrenamiento de Modelos
```bash
python train_classifier.py
```

## ğŸ¯ Uso del Sistema

### AplicaciÃ³n Principal

Ejecutar la interfaz grÃ¡fica:
```bash
python src/main.py
```

### Funcionalidades de la GUI

- **Vista en tiempo real** de la cÃ¡mara con detecciÃ³n de poses
- **ClasificaciÃ³n automÃ¡tica** de actividades
- **VisualizaciÃ³n de Ã¡ngulos articulares** y inclinaciones
- **Ajuste de umbrales** de detecciÃ³n en tiempo real
- **Historial de actividades** detectadas
- **Pistas visuales** para guiar al usuario

## ğŸ“· Capturas del Programa

AquÃ­ se muestran algunas capturas de pantalla del sistema en funcionamiento:

**Caminando hacia la cÃ¡mara:**
![Caminando hacia la cÃ¡mara](docs/caminando_hacia_camara.png)

**Caminando alejÃ¡ndose de la cÃ¡mara:**
![Caminando alejÃ¡ndose de la cÃ¡mara](docs/caminando_regreso_camara.png)

**Girar 90 grados:**
![Girar 90 grados](docs/girar_90.png)

**Girar 180 grados:**
![Girar 180 grados](docs/girar_180.png)

**SentÃ¡ndose:**
![SentÃ¡ndose](docs/sentandose.png)

**PoniÃ©ndose de pie:**
![PoniÃ©ndose de pie](docs/poniendose_de_pie.png)

## ğŸ“Š AnÃ¡lisis y Resultados

### UbicaciÃ³n de los Resultados Detallados
Los resultados detallados del anÃ¡lisis y la evaluaciÃ³n de modelos se pueden encontrar en los siguientes archivos:
- **AnÃ¡lisis Exploratorio**:
    - Reporte completo: `analysis/reports/analysis_report.json`
    - Visualizaciones y grÃ¡ficos: `analysis/plots/`
    - EstadÃ­sticas detalladas: `analysis/statistics/`
- **EvaluaciÃ³n de Modelos**:
    - ComparaciÃ³n de modelos: `models/evaluation/model_comparison.csv`
    - InformaciÃ³n del mejor modelo: `models/evaluation/best_model_info.json`
    - GrÃ¡ficos de evaluaciÃ³n: `models/plots/`

### Resumen del AnÃ¡lisis Exploratorio de Datos
(Basado en `analysis/reports/analysis_report.json`)

- **InformaciÃ³n General del Dataset**:
    - Fecha del anÃ¡lisis: 2025-06-04
    - Total de muestras: 1849
    - Total de caracterÃ­sticas analizadas: 101
    - Actividades: `caminarHacia`, `caminarRegreso`, `girar180`, `girar90`, `ponerseDePie`, `sentarse`.
- **DistribuciÃ³n de Muestras por Actividad**:
    - `girar180`: 369 muestras
    - `girar90`: 369 muestras
    - `caminarHacia`: 355 muestras
    - `ponerseDePie`: 267 muestras
    - `sentarse`: 250 muestras
    - `caminarRegreso`: 239 muestras
- El reporte completo (`analysis_report.json`) contiene estadÃ­sticas descriptivas detalladas (media, desviaciÃ³n estÃ¡ndar, etc.) para cada caracterÃ­stica, desglosadas por actividad.

### Resumen de EvaluaciÃ³n de Modelos
(Basado en `models/evaluation/model_comparison.csv` y `models/evaluation/best_model_info.json`)

Se evaluaron varios modelos de Machine Learning. La siguiente tabla resume su rendimiento:

| Modelo             | Accuracy | Precision | Recall   | F1-Score |
| :----------------- | :------- | :-------- | :------- | :------- |
| RandomForest       | 0.6541   | 0.6563    | 0.6541   | 0.6551   |
| SVM                | 0.6649   | 0.6599    | 0.6649   | 0.6603   |
| **LogisticRegression** | **0.6946** | **0.6930**  | **0.6946** | **0.6933** |
| GradientBoosting   | 0.6757   | 0.6757    | 0.6757   | 0.6757   |
| KNN                | 0.6649   | 0.6564    | 0.6649   | 0.6598   |
| XGBoost            | 0.6703   | 0.6705    | 0.6703   | 0.6703   |

- **Mejor Modelo**: `LogisticRegression`
    - Accuracy: ~69.46%
    - Precision: ~69.30%
    - Recall: ~69.46%
    - F1-Score: ~69.33%

Estos resultados indican que el modelo de RegresiÃ³n LogÃ­stica ofreciÃ³ el mejor rendimiento general para la clasificaciÃ³n de las actividades definidas.

### MÃ©tricas Principales

El sistema evalÃºa los modelos usando:
- **Accuracy**: PrecisiÃ³n general
- **Precision**: PrecisiÃ³n por clase
- **Recall**: Sensibilidad por clase
- **F1-Score**: Media armÃ³nica de precisiÃ³n y recall

## ğŸ”§ ConfiguraciÃ³n Avanzada

### Modelos Disponibles

El sistema entrena mÃºltiples algoritmos:
- **Random Forest**: Robusto y rÃ¡pido
- **SVM**: Efectivo para datos de alta dimensiÃ³n
- **Logistic Regression**: Simple y interpretable
- **Gradient Boosting**: Potente para patrones complejos
- **K-Nearest Neighbors**: Bueno para decisiones locales
- **XGBoost**: Opcional, requiere instalaciÃ³n adicional

### PersonalizaciÃ³n de ParÃ¡metros

Puedes ajustar parÃ¡metros en los scripts:

```bash
# Seleccionar nÃºmero de caracterÃ­sticas
python train_classifier.py --n_features 30

# Cambiar validation folds
python train_classifier.py --cv_folds 3

# Usar archivo especÃ­fico de datos
python train_classifier.py --data_file mi_dataset.csv
```

## ğŸ“ˆ MetodologÃ­a CRISP-DM

El proyecto sigue la metodologÃ­a CRISP-DM:

1. **ComprensiÃ³n del Negocio**: DetecciÃ³n de actividades humanas
2. **ComprensiÃ³n de Datos**: AnÃ¡lisis de videos y landmarks
3. **PreparaciÃ³n de Datos**: ExtracciÃ³n y normalizaciÃ³n de caracterÃ­sticas
4. **Modelado**: Entrenamiento de mÃºltiples algoritmos
5. **EvaluaciÃ³n**: MÃ©tricas de rendimiento y validaciÃ³n cruzada
6. **Despliegue**: AplicaciÃ³n en tiempo real

## ğŸ¤– Aspectos TÃ©cnicos

### DetecciÃ³n de Poses

- **MediaPipe Pose**: DetecciÃ³n de 33 landmarks corporales
- **NormalizaciÃ³n**: Coordenadas relativas al centro de cadera
- **Filtrado**: Suavizado de landmarks para reducir ruido

### ExtracciÃ³n de CaracterÃ­sticas

- **Coordenadas de landmarks**: x, y, z normalizadas
- **Ãngulos articulares**: Rodillas, caderas, codos
- **CaracterÃ­sticas geomÃ©tricas**: Distancias y proporciones
- **CaracterÃ­sticas temporales**: Velocidades y aceleraciones

### ClasificaciÃ³n

- **Enfoque hÃ­brido**: Reglas + Machine Learning
- **CaracterÃ­sticas seleccionadas**: Top N mÃ¡s relevantes
- **ValidaciÃ³n cruzada**: EvaluaciÃ³n robusta
- **OptimizaciÃ³n**: Grid Search para hiperparÃ¡metros

## ğŸ” ResoluciÃ³n de Problemas

### Problemas Comunes

1. **Error de cÃ¡mara**:
   - Verificar que la cÃ¡mara no estÃ© en uso
   - Probar con diferentes Ã­ndices de cÃ¡mara

2. **Baja precisiÃ³n**:
   - Agregar mÃ¡s videos de entrenamiento
   - Mejorar calidad de iluminaciÃ³n
   - Ajustar umbrales de detecciÃ³n

3. **Rendimiento lento**:
   - Reducir resoluciÃ³n de video
   - Usar modo rÃ¡pido (--quick_run)
   - Cerrar otras aplicaciones

### Logs y DepuraciÃ³n

- Los logs se muestran en consola durante la ejecuciÃ³n
- Los errores se guardan en archivos de salida
- Usar `--verbose` para mÃ¡s informaciÃ³n detallada

### Estructura de CÃ³digo

- **DocumentaciÃ³n**: Docstrings en todas las funciones
- **Estilo**: Seguir PEP 8
- **Testing**: Agregar tests para nuevas funcionalidades

## ğŸ“š Referencias y Bibliografia

### TecnologÃ­as Utilizadas

- [MediaPipe](https://ai.google.dev/edge/mediapipe/solutions/guide) - DetecciÃ³n de poses
- [OpenCV](https://opencv.org/) - Procesamiento de video
- [scikit-learn](https://scikit-learn.org/) - Machine Learning
- [PyQt5](https://pypi.org/project/PyQt5/) - Interfaz grÃ¡fica

### ArtÃ­culos de Referencia

- Pose Detection and Activity Recognition using MediaPipe
- Human Activity Recognition: A Comprehensive Survey
- Real-time Activity Classification in Video Streams